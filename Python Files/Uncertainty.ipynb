{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Model and evaluation\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame shape: (102319, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ProcessID</th>\n",
       "      <th>AssetID</th>\n",
       "      <th>AlarmSeverityName</th>\n",
       "      <th>State</th>\n",
       "      <th>TransactionMessage</th>\n",
       "      <th>Stage</th>\n",
       "      <th>AlarmClassName</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Season</th>\n",
       "      <th>Hour</th>\n",
       "      <th>ProcessedMessage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/1/2018 22:45</td>\n",
       "      <td>IBMS/201801024100783</td>\n",
       "      <td>1-JK1-JK1-01-E.02-AC-ACON-VAVU-0047</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>A2N</td>\n",
       "      <td>VAV-J09-01-029 SPACE TEMP ALARM</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>General-ELV</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>22</td>\n",
       "      <td>vavj0901029 space temp alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/1/2018 1:41</td>\n",
       "      <td>IBMS/201801024101029</td>\n",
       "      <td>1-JK1-JK1-00-C.27-AC-ACON-VAVU-0019</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>A2N</td>\n",
       "      <td>VAV-J09-00-027 SPACE TEMP ALARM</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>General-ELV</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>vavj0900027 space temp alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/2018 3:08</td>\n",
       "      <td>IBMS/201801034101175</td>\n",
       "      <td>1-JK1-JK1-00-C.27-AC-ACON-VAVU-0019</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>A2N</td>\n",
       "      <td>VAV-J09-00-027 SPACE TEMP ALARM</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>General-ELV</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3</td>\n",
       "      <td>vavj0900027 space temp alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/1/2018 7:12</td>\n",
       "      <td>IBMS/201801034101667</td>\n",
       "      <td>1-JK1-JK1-00-D.01-AC-ACON-VAVU-0021</td>\n",
       "      <td>3 - Low</td>\n",
       "      <td>A2N</td>\n",
       "      <td>VAV-J09-00-029 SPACE TEMP ALARM</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>General-ELV</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>7</td>\n",
       "      <td>vavj0900029 space temp alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/1/2018 9:04</td>\n",
       "      <td>IBMS/201801034102043</td>\n",
       "      <td>0-JK1-JK1-B2-1.01-AC-ACON-MAHU-0003</td>\n",
       "      <td>2 - Medium</td>\n",
       "      <td>A2N</td>\n",
       "      <td>MAU-JK1-B1-001 Dis Air Temp</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>General-ELV</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>maujk1b1001 dis air temp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DateTime             ProcessID                              AssetID  \\\n",
       "0  2/1/2018 22:45  IBMS/201801024100783  1-JK1-JK1-01-E.02-AC-ACON-VAVU-0047   \n",
       "1   3/1/2018 1:41  IBMS/201801024101029  1-JK1-JK1-00-C.27-AC-ACON-VAVU-0019   \n",
       "2   3/1/2018 3:08  IBMS/201801034101175  1-JK1-JK1-00-C.27-AC-ACON-VAVU-0019   \n",
       "3   3/1/2018 7:12  IBMS/201801034101667  1-JK1-JK1-00-D.01-AC-ACON-VAVU-0021   \n",
       "4   3/1/2018 9:04  IBMS/201801034102043  0-JK1-JK1-B2-1.01-AC-ACON-MAHU-0003   \n",
       "\n",
       "  AlarmSeverityName State               TransactionMessage      Stage  \\\n",
       "0           3 - Low   A2N  VAV-J09-01-029 SPACE TEMP ALARM  Cancelled   \n",
       "1           3 - Low   A2N  VAV-J09-00-027 SPACE TEMP ALARM  Cancelled   \n",
       "2           3 - Low   A2N  VAV-J09-00-027 SPACE TEMP ALARM  Cancelled   \n",
       "3           3 - Low   A2N  VAV-J09-00-029 SPACE TEMP ALARM  Cancelled   \n",
       "4        2 - Medium   A2N      MAU-JK1-B1-001 Dis Air Temp  Cancelled   \n",
       "\n",
       "  AlarmClassName  Year  Month  Day  DayOfWeek  Season  Hour  \\\n",
       "0    General-ELV  2018      1    2    Tuesday  Winter    22   \n",
       "1    General-ELV  2018      1    3  Wednesday  Winter     1   \n",
       "2    General-ELV  2018      1    3  Wednesday  Winter     3   \n",
       "3    General-ELV  2018      1    3  Wednesday  Winter     7   \n",
       "4    General-ELV  2018      1    3  Wednesday  Winter     9   \n",
       "\n",
       "               ProcessedMessage  \n",
       "0  vavj0901029 space temp alarm  \n",
       "1  vavj0900027 space temp alarm  \n",
       "2  vavj0900027 space temp alarm  \n",
       "3  vavj0900029 space temp alarm  \n",
       "4      maujk1b1001 dis air temp  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace this with the path or method to load your actual dataset\n",
    "df = pd.read_csv(\"../Dataset/preprocessed_trendedpointalarm.csv\")\n",
    "\n",
    "# Quick look at the data\n",
    "print(\"Initial DataFrame shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "DateTime             63331\n",
      "AssetID                271\n",
      "AlarmSeverityName        0\n",
      "State                    0\n",
      "Stage                 2984\n",
      "AlarmClassName           0\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "DayOfWeek                0\n",
      "Season                   0\n",
      "Hour                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Convert DateTime to datetime type\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], errors='coerce')\n",
    "\n",
    "# 3.2 Drop unnecessary columns (example columns to drop—modify as needed)\n",
    "cols_to_drop = ['ProcessID', 'TransactionMessage', 'ProcessedMessage']\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# 3.3 Check for missing values\n",
    "print(\"Missing values before imputation:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['AssetID', 'State', 'Stage', 'AlarmClassName', 'Year', 'Month', 'Day', 'DayOfWeek', 'Season', 'Hour']\n",
      "Target: AlarmSeverityName\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Target variable\n",
    "target_col = 'AlarmSeverityName'\n",
    "\n",
    "# 4.2 Features\n",
    "feature_cols = [col for col in df.columns if col not in [target_col, 'DateTime']]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"Features:\", feature_cols)\n",
    "print(\"Target:\", target_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype('category')\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\3591638281.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Detect categorical columns (object or category dtype)\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Convert them to category if not already\n",
    "for col in cat_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "\n",
    "# Label-encode the categorical columns to ensure your final dataset X has only numeric columns\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 5.2 Remove rare classes(for example if \"Low\" repeats only once that would be a rare class) in the target (any class with <=1 occurrence, for example)\n",
    "y_counts = y.value_counts()\n",
    "rare_classes = y_counts[y_counts <= 1].index\n",
    "df = df[~df[target_col].isin(rare_classes)]\n",
    "\n",
    "# Update X and y after removing rare-class rows\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\269589844.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\269589844.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\269589844.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\269589844.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\269589844.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n",
      "C:\\Users\\Soroush\\AppData\\Local\\Temp\\ipykernel_19388\\269589844.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col].astype(str))\n"
     ]
    }
   ],
   "source": [
    "# Reapply Label Encoding to categorical columns in X\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    # Optionally, store the encoder for later use:\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Label-encode the target variable as well\n",
    "target_encoder = LabelEncoder()\n",
    "y = target_encoder.fit_transform(y.astype(str))\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Proceed to split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Preserves class distribution\n",
    ")\n",
    "\n",
    "# Convert X_train and X_test to DataFrames with proper column names\n",
    "if not isinstance(X_train, pd.DataFrame):\n",
    "    X_train = pd.DataFrame(X_train, columns=feature_cols)\n",
    "if not isinstance(X_test, pd.DataFrame):\n",
    "    X_test = pd.DataFrame(X_test, columns=feature_cols)\n",
    "\n",
    "# Optionally, convert all columns to numeric (they should already be numeric now)\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: [51233 13449 16928    83   125    36]\n",
      "Class distribution after SMOTE: [51233 51233 51233 51233 51233 51233]\n"
     ]
    }
   ],
   "source": [
    "# Ensure X_train is a DataFrame (if it isn’t already)\n",
    "if not isinstance(X_train, pd.DataFrame):\n",
    "    X_train = pd.DataFrame(X_train, columns=feature_cols)  # assign appropriate column names\n",
    "\n",
    "# Identify categorical columns (those of object type)\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Do the same for your test set if needed:\n",
    "if isinstance(X_test, np.ndarray):\n",
    "    X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "else:\n",
    "    for col in categorical_cols:\n",
    "        X_test[col] = label_encoders[col].transform(X_test[col].astype(str))\n",
    "\n",
    "# Now, try SMOTE again by generating synthetic samples for the minority classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution before SMOTE:\", np.bincount(y_train))\n",
    "print(\"Class distribution after SMOTE:\", np.bincount(y_train_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size before outlier removal: 307398\n",
      "Training set size after outlier removal: 304329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Apply IsolationForest on the SMOTE-resampled training data\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "y_train_outliers = iso_forest.fit_predict(X_train_sm)  # X_train_sm from SMOTE\n",
    "\n",
    "# Keep only inliers (labels == 1)\n",
    "inlier_mask = (y_train_outliers == 1)\n",
    "X_train_clean = X_train_sm[inlier_mask]\n",
    "y_train_clean = y_train_sm[inlier_mask]\n",
    "\n",
    "print(\"Training set size before outlier removal:\", X_train_sm.shape[0])\n",
    "print(\"Training set size after outlier removal:\", X_train_clean.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection BEFORE scaling\n",
    "iso_forest_orig = IsolationForest(contamination=0.01, random_state=42)\n",
    "outlier_preds_orig = iso_forest_orig.fit_predict(X_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "# Apply RobustScaler on the SMOTE-resampled training data\n",
    "scaler = RobustScaler()\n",
    "X_train_sm_scaled = scaler.fit_transform(X_train_sm)\n",
    "\n",
    "# Initialize IsolationForest for the scaled data\n",
    "iso_forest_scaled = IsolationForest(contamination=0.01, random_state=42)\n",
    "outlier_preds_scaled = iso_forest_scaled.fit_predict(X_train_sm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:30:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:30:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:30:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:30:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Soroush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:30:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Convert y_train_clean to a pandas Series\n",
    "y_train_clean_series = pd.Series(y_train_clean)\n",
    "\n",
    "seeds = [42, 123, 999, 31415, 2718]\n",
    "models_list = []\n",
    "\n",
    "for seed in seeds:\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # Generate bootstrap indices\n",
    "    boot_indices = rng.choice(len(X_train_clean), size=len(X_train_clean), replace=True)\n",
    "    X_boot = X_train_clean.iloc[boot_indices]       # X_train_clean is a DataFrame\n",
    "    y_boot = y_train_clean_series.iloc[boot_indices]  # Now you can use .iloc on the Series\n",
    "\n",
    "    # Initialize XGBoost with some randomness\n",
    "    model_ens = XGBClassifier(\n",
    "        random_state=seed,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "\n",
    "    model_ens.fit(X_boot, y_boot)\n",
    "    models_list.append(model_ens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static three classes in a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Mar/2025 10:08:15] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightningchart.charts.dashboard.Dashboard at 0x23b48abf150>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightningchart as lc\n",
    "import numpy as np\n",
    "\n",
    "lc.set_license('my-license-key')\n",
    "\n",
    "predictions_for_class0 = []\n",
    "predictions_for_class1 = []\n",
    "predictions_for_class2 = []\n",
    "\n",
    "for m in models_list:\n",
    "    proba = m.predict_proba(X_test)  # shape: (num_samples, n_classes)\n",
    "    # Append the probabilities for each class\n",
    "    predictions_for_class0.append(proba[:, 0])  # Class=0 (Low)\n",
    "    predictions_for_class1.append(proba[:, 1])  # Class=1 (Medium)\n",
    "    predictions_for_class2.append(proba[:, 2])  # Class=2 (High)\n",
    "\n",
    "# Convert each list into a NumPy array of shape (num_models, num_samples)\n",
    "predictions_for_class0 = np.array(predictions_for_class0)  # (num_models, num_samples)\n",
    "predictions_for_class1 = np.array(predictions_for_class1)\n",
    "predictions_for_class2 = np.array(predictions_for_class2)\n",
    "\n",
    "# --- 2) Helper function to create a chart with uncertainty bands. ---\n",
    "def create_uncertainty_chart(dashboard, row_idx, col_idx, predictions_array, class_label):\n",
    "    \"\"\"\n",
    "    Creates a chart in the given (row_idx, col_idx) of the Dashboard showing:\n",
    "      - Median line\n",
    "      - 5–95% band (outer)\n",
    "      - 25–75% band (inner)\n",
    "    for a set of predictions_array shaped (num_models, num_samples).\n",
    "    \"\"\"\n",
    "    # Compute percentiles\n",
    "    median_pred = np.median(predictions_array, axis=0)\n",
    "    p5 = np.percentile(predictions_array, 5, axis=0)\n",
    "    p25 = np.percentile(predictions_array, 25, axis=0)\n",
    "    p75 = np.percentile(predictions_array, 75, axis=0)\n",
    "    p95 = np.percentile(predictions_array, 95, axis=0)\n",
    "\n",
    "    # Sort by median for a smoother band\n",
    "    order = np.argsort(median_pred)\n",
    "    x_sorted = np.arange(len(order)).tolist()\n",
    "    median_sorted = median_pred[order].tolist()\n",
    "    p5_sorted = p5[order].tolist()\n",
    "    p25_sorted = p25[order].tolist()\n",
    "    p75_sorted = p75[order].tolist()\n",
    "    p95_sorted = p95[order].tolist()\n",
    "\n",
    "    # Create chart for this class\n",
    "    chart = dashboard.ChartXY(row_index=row_idx, column_index=col_idx, \n",
    "                              title=f\"Uncertainty Band (Class={class_label})\")\n",
    "\n",
    "    # Create the median line series\n",
    "    median_series = chart.add_line_series(data_pattern=\"ProgressiveX\")\n",
    "    median_series.append_samples(x_values=x_sorted,\n",
    "                                 y_values=[float(val) for val in median_sorted])\n",
    "    median_series.set_name(f\"Median (Class={class_label})\")\n",
    "\n",
    "    # Outer polygon: 5th-95th percentile\n",
    "    outer_polygon = chart.add_area_series()\n",
    "    outer_points = []\n",
    "    for x, y in zip(x_sorted, p5_sorted):\n",
    "        outer_points.append({\"x\": float(x), \"y\": float(y)})\n",
    "    for x, y in zip(x_sorted[::-1], p95_sorted[::-1]):\n",
    "        outer_points.append({\"x\": float(x), \"y\": float(y)})\n",
    "    outer_polygon.add(outer_points)\n",
    "    outer_polygon.set_fill_color(lc.Color(0, 0, 255))  # Blue\n",
    "    outer_polygon.set_name(\"5th–95th Percentile\")\n",
    "\n",
    "    # Inner polygon: 25th-75th percentile\n",
    "    inner_polygon = chart.add_area_series()\n",
    "    inner_points = []\n",
    "    for x, y in zip(x_sorted, p25_sorted):\n",
    "        inner_points.append({\"x\": float(x), \"y\": float(y)})\n",
    "    for x, y in zip(x_sorted[::-1], p75_sorted[::-1]):\n",
    "        inner_points.append({\"x\": float(x), \"y\": float(y)})\n",
    "    inner_polygon.add(inner_points)\n",
    "    inner_polygon.set_fill_color(lc.Color(255, 255, 0))  # Yellow\n",
    "    inner_polygon.set_name(\"25th–75th Percentile\")\n",
    "\n",
    "    # Create and add legend with the three series\n",
    "    legend = chart.add_legend()\n",
    "    legend.add(median_series)\n",
    "    legend.add(outer_polygon)\n",
    "    legend.add(inner_polygon)\n",
    "    legend.set_title(\"Legend\")\n",
    "\n",
    "    chart.get_default_x_axis().set_title(\"Sorted Sample Index\")\n",
    "    chart.get_default_y_axis().set_title(\"Predicted Probability\")\n",
    "    return chart\n",
    "\n",
    "# --- 3) Create a 3-row dashboard (one chart per class). ---\n",
    "dashboard = lc.Dashboard(rows=3, columns=1, theme=lc.Themes.Light)\n",
    "\n",
    "# Row 0 -> Class 0 (Low severity)\n",
    "create_uncertainty_chart(\n",
    "    dashboard=dashboard,\n",
    "    row_idx=0,\n",
    "    col_idx=0,\n",
    "    predictions_array=predictions_for_class0,\n",
    "    class_label=\"Low\"\n",
    ")\n",
    "\n",
    "# Row 1 -> Class 1 (Medium severity)\n",
    "create_uncertainty_chart(\n",
    "    dashboard=dashboard,\n",
    "    row_idx=1,\n",
    "    col_idx=0,\n",
    "    predictions_array=predictions_for_class1,\n",
    "    class_label=\"Medium\"\n",
    ")\n",
    "create_uncertainty_chart(\n",
    "    dashboard=dashboard,\n",
    "    row_idx=2,\n",
    "    col_idx=0,\n",
    "    predictions_array=predictions_for_class2,\n",
    "    class_label=\"High\"\n",
    ")\n",
    "\n",
    "dashboard.open(method=\"browser\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
